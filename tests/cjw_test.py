# from dotenv import load_dotenv
# import openai
# import re
# import os
#
# load_dotenv()
# openai.api_base = os.getenv("OPENAI_BASE_URL")
# openai.api_key = os.getenv("OPENAI_API_KEY")
#
# sys_eval_prompt = '''# Role: Evaluator of Tweet Novelty
#
#         ## Profile
#         - version: 1.0
#         - language: English
#         - description: Evaluate the novelty of tweets generated by a language model on a scale from 1 to 10, where 1 indicates low novelty and 10 indicates highly original and innovative content.
#
#         ## Skills
#         1. Assessing content for originality and creativity.
#         2. Identifying repetitive or derivative content.
#         3. Providing reasoning for the assigned score to justify the evaluation.
#
#         ## Background (optional):
#         The goal is to evaluate the originality of language model outputs when generating tweets, focusing on their uniqueness, creativity, and potential to engage audiences.
#
#         ## Goals:
#         - To identify the degree of novelty in generated tweets.
#         - To help improve LLM prompt tuning and output quality.
#
#         ## Output Format:
#         For each tweet, provide the following:
#         Rating: [score]
#         Explanation: [brief reasoning for the assigned score].
#
#         ## Rules
#         1. Consider the following factors when assigning a score:
#            - Originality: Is the idea fresh and unique, or is it a rehash of common themes?
#            - Creativity: Does the tweet present the idea in a surprising or engaging manner?
#            - Engagement: Does the tweet have the potential to capture attention based on its novelty?
#         2. Scores should be justified with a concise explanation.
#
#         ## Workflows
#         1. Analyze the tweet content for signs of repetition, cliché, or predictability.
#         2. Determine if the tweet presents an idea in an innovative or unexpected way.
#         3. Assign a score from 1 (very low novelty) to 10 (extremely high novelty) based on the analysis.
#         4. Provide a short explanation of the score, referencing specific aspects of the tweet that influenced the rating.
#
#         ## Init
#         Evaluate the following tweets for novelty using the provided scale and guidelines. For each tweet, assign a Rating and provide an Explanation.
#         '''
# prompt_input = [
#     {"role": "system", "content": [{"type": "text", "text": sys_eval_prompt}]},
#     {"role": "user", "content": [{"type": "text", "text": "This is the tweet:"+" 震惊！国家主席换了"}]},
# ]
# response = openai.ChatCompletion.create(
#     model='gpt-4o-2024-11-20',
#     messages=prompt_input,
#     max_tokens=4096,
#     temperature=0,
# )
# answer = [choice["message"]["content"] for choice in response["choices"]][0]
#
# # 提取Rating
# rating_match = re.search(r"Rating:\s*(\d+)", answer)
# if rating_match:
#     rating = rating_match.group(1)
# else:
#     rating = None
#
# # 提取Explanation
# explanation_match = re.search(r"Explanation:\s*(.*)", answer, re.DOTALL)
# if explanation_match:
#     explanation = explanation_match.group(1).strip()
# else:
#     explanation = None
#
# print("Rating:", rating)
# print("Explanation:", explanation)
# print(answer)

# from playwright.sync_api import sync_playwright
# import json
#
# def run(playwright):
#     browser = playwright.chromium.launch(headless=False)  # 或者使用 'firefox' 或 'webkit'
#     context = browser.new_context()
#
#     # 从文件加载 cookies
#     try:
#         with open('taobao.json', 'r') as f:
#             cookies = json.load(f)
#             context.add_cookies(cookies)
#     except FileNotFoundError:
#         print("Cookies file not found. Will proceed with new login.")
#
#     page = context.new_page()
#     page.goto('https://www.amazon.com/s?k=acetic+acid&crid=3KNZCZBYTRSSP&sprefix=acetic+acid%2Caps%2C476&ref=nb_sb_noss_1')  # 你的目标网址
#
#     coupon_button = page.locator('button:text("Add to cart")')
#     print(coupon_button)
#     if coupon_button.count() > 0:
#         coupon_button.first.click()
#         print("领券购买按钮已点击")
#     else:
#         print("没有找到领券购买按钮")
#
#     # 在这里添加需要的网页交互或检查
#
#     # 等待用户输入，防止脚本结束后立即关闭浏览器
#     input("Press Enter to close browser...")
#
#     # # 保存 cookies 到文件，如果需要
#     # with open('taobao.json', 'w') as f:
#     #     json.dump(context.cookies(), f)
#
#     context.close()
#     browser.close()
#
# with sync_playwright() as playwright:
#     run(playwright)

# from playwright.sync_api import sync_playwright
# import json
#
# def run(playwright):
#     browser = playwright.chromium.launch(headless=False, args=['--disable-blink-features=AutomationControlled'])  # 或者使用 'firefox' 或 'webkit'
#     context = browser.new_context()
#
#     # 从文件加载 cookies
#     try:
#         with open('google_keep.json', 'r') as f:
#             cookies = json.load(f)
#             context.add_cookies(cookies)
#     except FileNotFoundError:
#         print("Cookies file not found. Will proceed with new login.")
#
#     page = context.new_page()
#     try:
#         page.goto('https://keep.google.com/', timeout=60000, wait_until='load')  # 等待页面完全加载
#     except Exception as e:
#         print(f"Error navigating to the site: {str(e)}")
#         return  # 如果加载失败，提前结束函数
#
#     # 在这里添加需要的网页交互或检查
#
#     # 等待用户输入，防止脚本结束后立即关闭浏览器
#     input("Press Enter to close browser...")
#
#     # 保存 cookies 到文件，如果需要
#     with open('google_keep.json', 'w') as f:
#         json.dump(context.cookies(), f)
#
#     context.close()
#     browser.close()
#
# with sync_playwright() as playwright:
#     run(playwright)

import pandas as pd

# 读取 Parquet 文件
df = pd.read_parquet("./data/test_task-00004-of-00005-a3a487e53da307b4.parquet")

# 提取第一行
first_row = df.iloc[0]

# 将第一行存储为 Excel 文件
first_row.to_frame().T.to_excel("first_row.xlsx", index=False)

print("第一行数据已保存到 'first_row.xlsx'")




